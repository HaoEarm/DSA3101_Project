# -*- coding: utf-8 -*-
"""sentiment_analysis_nps_score_wordcloud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kzDEVwWJgf7JcH13oSfx-ioim1DR9b1y
"""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
from wordcloud import WordCloud, STOPWORDS

all_data = pd.read_csv("https://raw.githubusercontent.com/HaoEarm/DSA3101_Project/main/Data/predictions.csv")
all_data = all_data.drop(columns=['Unnamed: 0'])
all_data['No.'] = all_data.reset_index().index
gxs_data = all_data[all_data['Bank'] == 'GXS Bank']
other_banks = all_data[all_data['Bank'] != 'GXS Bank']

#Plot 1 - overall sentiment analysis of gxs data
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))
# Plot histogram for Positive scores
ax1.hist(gxs_data['Positive'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
ax1.set_title('Histogram of Positive Scores')
ax1.set_xlabel('Positive Score')
ax1.set_ylabel('Frequency')
ax1.grid(True)

# Plot histogram for Negative scores
ax2.hist(gxs_data['Negative'], bins=20, color='salmon', edgecolor='black', alpha=0.7)
ax2.set_title('Histogram of Negative Scores')
ax2.set_xlabel('Negative Score')
ax2.set_ylabel('Frequency')
ax2.grid(True)

plt.show()

# Filter the DataFrame
filtered_positive_df = gxs_data[gxs_data['Score'] > 3]
filtered_neutral_df = gxs_data[gxs_data['Score'] == 3]
filtered_negative_df = gxs_data[gxs_data['Score'] < 3]

#able to indetify 5 star reveiws with actual negative sentiment
anomalies_pos = filtered_positive_df[filtered_positive_df['Positive'] < 0.4]
#for x in anomalies_pos['Review']:
#  print(x)

#print("====================================")
#some reviews are positive but struggles to guage sentiment on misspelt and questions
anomalies_neg = filtered_negative_df[filtered_negative_df['Positive'] > 0.8]
#for x in anomalies_neg['Review']:
#  print(x)

#Plot 2 - breakdown for other banks
# Filter the DataFrame
filtered_positive_df = gxs_data[gxs_data['Score'] > 3]
filtered_neutral_df = gxs_data[gxs_data['Score'] == 3]
filtered_negative_df = gxs_data[gxs_data['Score'] < 3]

# Create subplots
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))

# Plot positive scores histogram
ax1.hist(filtered_positive_df['Positive'], bins=10, color='green', alpha=0.7)
ax1.set_xlabel('Positive Score')
ax1.set_ylabel('Frequency')
ax1.set_title('General Positive Sentiment of Scores Above 3')


# Plot neutral scores histogram
ax2.hist(filtered_neutral_df['Positive'], bins=10, color='blue', alpha=0.7)
ax2.set_xlabel('Positive Score')
ax2.set_ylabel('Frequency')
ax2.set_title('General Positive Sentiment of Scores Equal to 3')


# Plot negative scores histogram
ax3.hist(filtered_negative_df['Positive'], bins=10, color='red', alpha=0.7)
ax3.set_xlabel('Positive Score')
ax3.set_ylabel('Frequency')
ax3.set_title('General Positive Sentiment of Scores Below 3')

# Show the plot
plt.show()

# Create subplots - breakdown for other banks
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))

# Plot positive scores histogram
ax1.hist(filtered_positive_df['Negative'], bins=10, color='green', alpha=0.7)
ax1.set_xlabel('Negative Score')
ax1.set_ylabel('Frequency')
ax1.set_title('General Negative Sentiment of Scores Above 3')

# Plot neutral scores histogram
ax2.hist(filtered_neutral_df['Negative'], bins=10, color='blue', alpha=0.7)
ax2.set_xlabel('Negative Score')
ax2.set_ylabel('Frequency')
ax2.set_title('General Negative Sentiment of Scores Equal To 3')

# Plot negative scores histogram
ax3.hist(filtered_negative_df['Negative'], bins=10, color='red', alpha=0.7)
ax3.set_xlabel('Negative Score')
ax3.set_ylabel('Frequency')
ax3.set_title('General Negative Sentiment of Scores Below 3')

# Show the plot
plt.show()

#Plot 1 - overall sentiment analysis for other banks
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))
# Plot histogram for Positive scores
ax1.hist(other_banks['Positive'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
ax1.set_title('Histogram of Positive Scores')
ax1.set_xlabel('Positive Score')
ax1.set_ylabel('Frequency')
ax1.grid(True)

# Plot histogram for Negative scores
ax2.hist(other_banks['Negative'], bins=20, color='salmon', edgecolor='black', alpha=0.7)
ax2.set_title('Histogram of Negative Scores')
ax2.set_xlabel('Negative Score')
ax2.set_ylabel('Frequency')
ax2.grid(True)

plt.show()

#Plot 2 - breakdown for other banks
# Filter the DataFrame
filtered_positive_df = other_banks[other_banks['Score'] > 3]
filtered_neutral_df = other_banks[other_banks['Score'] == 3]
filtered_negative_df = other_banks[other_banks['Score'] < 3]

# Create subplots
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))

# Plot positive scores histogram
ax1.hist(filtered_positive_df['Positive'], bins=10, color='green', alpha=0.7)
ax1.set_xlabel('Positive Score')
ax1.set_ylabel('Frequency')
ax1.set_title('General Positive Sentiment of Scores Above 3')


# Plot neutral scores histogram
ax2.hist(filtered_neutral_df['Positive'], bins=10, color='blue', alpha=0.7)
ax2.set_xlabel('Positive Score')
ax2.set_ylabel('Frequency')
ax2.set_title('General Positive Sentiment of Scores Equal to 3')


# Plot negative scores histogram
ax3.hist(filtered_negative_df['Positive'], bins=10, color='red', alpha=0.7)
ax3.set_xlabel('Positive Score')
ax3.set_ylabel('Frequency')
ax3.set_title('General Positive Sentiment of Scores Below 3')

# Show the plot
plt.show()

#Plot 2 - breakdown for other banks
# Filter the DataFrame
filtered_positive_df = other_banks[other_banks['Score'] > 3]
filtered_neutral_df = other_banks[other_banks['Score'] == 3]
filtered_negative_df = other_banks[other_banks['Score'] < 3]

# Create subplots
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))

# Plot positive scores histogram
ax1.hist(filtered_positive_df['Negative'], bins=10, color='green', alpha=0.7)
ax1.set_xlabel('Positive Score')
ax1.set_ylabel('Frequency')
ax1.set_title('General Positive Sentiment of Scores Above 3')


# Plot neutral scores histogram
ax2.hist(filtered_neutral_df['Negative'], bins=10, color='blue', alpha=0.7)
ax2.set_xlabel('Positive Score')
ax2.set_ylabel('Frequency')
ax2.set_title('General Positive Sentiment of Scores Equal to 3')


# Plot negative scores histogram
ax3.hist(filtered_negative_df['Negative'], bins=10, color='red', alpha=0.7)
ax3.set_xlabel('Positive Score')
ax3.set_ylabel('Frequency')
ax3.set_title('General Positive Sentiment of Scores Below 3')

# Show the plot
plt.show()

#NPS Score - using sentiments
def categorize_sentiment(score):
    if score > 0.85:
        return 'promoter'
    elif score >= 0.5:
        return 'passive'
    else:
        return 'detractor'

all_data['nps_category_sentiment'] = all_data['Positive'].apply(categorize_sentiment)

nps_scores = all_data.groupby('Bank')['nps_category_sentiment'].value_counts(normalize=True).unstack().fillna(0)
nps_scores['nps'] = nps_scores['promoter'] - nps_scores['detractor']

# Print NPS scores for each bank
#print("Net Promoter Scores (NPS) for each bank:")
#print(nps_scores)

plt.figure(figsize=(10, 6))
nps_scores['nps'].sort_values().plot(kind='bar', color='skyblue')
plt.title('Net Promoter Scores (NPS) for Each Bank')
plt.xlabel('Bank')
plt.ylabel('NPS')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

#NPS Score v2 - suing rating
conditions = [
    (all_data['Score'] <= 2),
    (all_data['Score'] == 3 ),
    (all_data['Score'] >= 4)
]

values = ['Detractor', 'Passive', 'Promoter']

all_data['NPS category Rating'] = np.select(conditions, values)
nps_scores = all_data.groupby('Bank')['NPS category Rating'].value_counts(normalize=True).unstack().fillna(0)
nps_scores['nps'] = nps_scores['Promoter'] - nps_scores['Detractor']
#print("Net Promoter Scores (NPS) for each bank:")
#print(nps_scores)

plt.figure(figsize=(10, 6))
nps_scores['nps'].sort_values().plot(kind='bar', color='skyblue')
plt.title('Net Promoter Scores (NPS) for Each Bank')
plt.xlabel('Bank')
plt.ylabel('NPS')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

#Postive Word Clouds - for gxs data
# Tokenization
gxs_data = all_data[all_data['Bank'] == 'GXS Bank']
promoter_reviews = gxs_data[gxs_data['NPS category Rating'] == 'Promoter']['Review']

promoter_reviews_tokenised = ""
for val in promoter_reviews:
    val = str(val)
    tokens = val.split()
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
    promoter_reviews_tokenised += " ".join(tokens)+" "
# Word Cloud
# https://medium.com/@harinisureshla/wordclouds-basics-of-nlp-5b60be226414
# Words to remove from the word cloud
words_to_remove = ["app", "singapore", "banking", "gxs", "love", "really", "easy", "bank","please", "best","set","nice","good","wait","smiling_face_with_heart", "much", "try","great"]

# Combine standard stopwords with custom words to remove
#stop_words = set(list(STOPWORDS) + words_to_remove)
stop_words = words_to_remove+ list(STOPWORDS)
positive_wordcloud = WordCloud(max_font_size=50, max_words=50, background_color="white", stopwords = stop_words).generate(str(promoter_reviews_tokenised))
plt.figure()
plt.title("Promoter Reviews - Wordcloud")
plt.imshow(positive_wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

#Negative wordcloud gxs data
# Tokenization
gxs_data = all_data[all_data['Bank'] == 'GXS Bank']
non_promoter_reviews = gxs_data[gxs_data['NPS category Rating'] != 'Promoter']['Review']

non_promoter_reviews_tokenised = ""
for val in non_promoter_reviews:
    val = str(val)
    tokens = val.split()
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
    non_promoter_reviews_tokenised += " ".join(tokens)+" "
# Word Cloud
# https://medium.com/@harinisureshla/wordclouds-basics-of-nlp-5b60be226414
# Words to remove from the word cloud
words_to_remove = ["app", "singapore", "banking", "gxs","great","account","money","bank","even","got","keep","good","easy","thumbs_down", "month","review","sign","open","first","trying","still","please","try","tried"]

# Combine standard stopwords with custom words to remove
#stop_words = set(list(STOPWORDS) + words_to_remove)
stop_words = words_to_remove+ list(STOPWORDS)
negative_wordcloud = WordCloud(max_font_size=50, max_words=50, background_color="white", stopwords = stop_words).generate(str(non_promoter_reviews_tokenised))
plt.figure()
plt.title("Detractor Reviews - Wordcloud")
plt.imshow(negative_wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

#Positive Word Cloud - other banks
other_data = all_data[all_data['Bank'] != 'GXS Bank']
promoter_reviews = other_data[other_data['NPS category Rating'] == 'Promoter']['Review']

promoter_reviews_tokenised = ""
for val in promoter_reviews:
    val = str(val)
    tokens = val.split()
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
    promoter_reviews_tokenised += " ".join(tokens)+" "
# Word Cloud
# https://medium.com/@harinisureshla/wordclouds-basics-of-nlp-5b60be226414
# Words to remove from the word cloud
words_to_remove = ["app", "singapore", "banking","wise","thank","love","day","far","nice","revolut","need","S"]

# Combine standard stopwords with custom words to remove
#stop_words = set(list(STOPWORDS) + words_to_remove)
stop_words = words_to_remove+ list(STOPWORDS)
positive_wordcloud = WordCloud(max_font_size=50, max_words=50, background_color="white", stopwords = stop_words).generate(str(promoter_reviews_tokenised))
plt.figure()
plt.title("Promoter Reviews - Wordcloud")
plt.imshow(positive_wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

#Negative Word Cloud - other banks
other_data = all_data[all_data['Bank'] != 'GXS Bank']
non_promoter_reviews = other_data[other_data['NPS category Rating'] != 'Promoter']['Review']

non_promoter_reviews_tokenised = ""
for val in non_promoter_reviews:
    val = str(val)
    tokens = val.split()
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
    non_promoter_reviews_tokenised += " ".join(tokens)+" "
# Word Cloud
# https://medium.com/@harinisureshla/wordclouds-basics-of-nlp-5b60be226414
# Words to remove from the word cloud
words_to_remove = ["app", "singapore", "banking","bank","still","revolut","even","wise","make","need","now","using","unable","used","fund","already","trust","keep","back","good","day","S","please","check","will","tried","go","reason","without","use","don t","account"]

# Combine standard stopwords with custom words to remove
#stop_words = set(list(STOPWORDS) + words_to_remove)
stop_words = words_to_remove+ list(STOPWORDS)
negative_wordcloud = WordCloud(max_font_size=50, max_words=50, background_color="white", stopwords = stop_words).generate(str(non_promoter_reviews_tokenised))
plt.figure()
plt.title("Detractor Reviews - Wordcloud")
plt.imshow(negative_wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()